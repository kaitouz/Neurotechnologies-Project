{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!unzip -d data /content/drive/MyDrive/Neuron/Audio_Speech_Actors_01-24.zip"
      ],
      "metadata": {
        "id": "3pgaYgbgg-pI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import librosa\n",
        "\n",
        "from sklearn.utils import shuffle"
      ],
      "metadata": {
        "id": "UZcEGSUR3Oz4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "current_path = 'data/'"
      ],
      "metadata": {
        "id": "qlGB3fPi4Xhz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_file_path_list(path):\n",
        "    ravdess_directory_list = os.listdir(path)\n",
        "    file_emotion = []\n",
        "    file_path = []\n",
        "    for dir in ravdess_directory_list:\n",
        "        actor = os.listdir(path + dir) \n",
        "        for file in actor:\n",
        "            part = file.split('.')[0]\n",
        "            part = part.split('-')\n",
        "            if len(part) != 7:\n",
        "                continue\n",
        "            file_emotion.append(int(part[2]))\n",
        "            file_path.append(path + dir + '/' + file)\n",
        "            \n",
        "    # dataframe for emotion of files\n",
        "    emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
        "\n",
        "    # dataframe for path of files.\n",
        "    path_df = pd.DataFrame(file_path, columns=['Path'])\n",
        "    Ravdess_df = pd.concat([emotion_df, path_df], axis=1)\n",
        "\n",
        "    # changing integers to actual emotions.\n",
        "    Ravdess_df.Emotions.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}, inplace=True)\n",
        "    Ravdess_df.to_csv(\"data_path.csv\",index=False)\n",
        "\n",
        "    temp = shuffle(Ravdess_df)\n",
        "    temp_bool = np.random.rand(len(temp)) < 0.8\n",
        "    train_df = temp[temp_bool]\n",
        "    test_df = temp[~temp_bool]\n",
        "    \n",
        "    train_df.to_csv(\"train_path.csv\",index=False)\n",
        "    test_df.to_csv(\"test_path.csv\",index=False)"
      ],
      "metadata": {
        "id": "Ynbfg0o-3Aek"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_file_path_list(current_path)"
      ],
      "metadata": {
        "id": "1esCLBT43MN3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = pd.read_csv('train_path.csv')\n",
        "train_df = pd.read_csv('train_path.csv')\n",
        "test_df = pd.read_csv('test_path.csv')"
      ],
      "metadata": {
        "id": "EaSzbZcL3cUm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def noise(data):\n",
        "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
        "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
        "    return data\n",
        "\n",
        "def stretch(data, rate=0.8):\n",
        "    return librosa.effects.time_stretch(data, rate)\n",
        "\n",
        "def shift(data):\n",
        "    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n",
        "    return np.roll(data, shift_range)\n",
        "\n",
        "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
        "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
        "\n",
        "# taking any example and checking for techniques.\n",
        "path = np.array(data_path.Path)[1]\n",
        "data, sample_rate = librosa.load(path)"
      ],
      "metadata": {
        "id": "1yAIqSVx4LW-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(data):\n",
        "    # taking a random example and checking for its sample_rate.\n",
        "    _ , sample_rate = librosa.load(current_path + \"Actor_01/03-01-01-01-01-01-01.wav\")\n",
        "\n",
        "    # ZCR\n",
        "    result = np.array([])\n",
        "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n",
        "    result = np.hstack((result, zcr)) # stacking horizontally\n",
        "\n",
        "    # Chroma_stft\n",
        "    stft = np.abs(librosa.stft(data))\n",
        "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
        "    result = np.hstack((result, chroma_stft)) # stacking horizontally\n",
        "\n",
        "    # MFCC\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate, n_mfcc=13).T, axis=0)\n",
        "    result = np.hstack((result, mfcc)) # stacking horizontally\n",
        "\n",
        "    # MelSpectogram\n",
        "    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n",
        "    result = np.hstack((result, mel)) # stacking horizontally\n",
        "\n",
        "    # Spectral constrat\n",
        "    spect_contr = np.mean(librosa.feature.spectral_contrast(data, sr=sample_rate).T, axis=0)\n",
        "    result = np.hstack((result, spect_contr))\n",
        "\n",
        "    return result\n",
        "\n",
        "def get_features(path, data_train=True):\n",
        "    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n",
        "    data, sample_rate = librosa.load(path, duration=2.5, offset=0.6)\n",
        "    \n",
        "    # without augmentation\n",
        "    result = np.array(extract_features(data))\n",
        "    \n",
        "    if data_train == False:\n",
        "        return result\n",
        "    else:\n",
        "        # data with noise\n",
        "        noise_data = noise(data)\n",
        "        result = np.vstack((result, extract_features(noise_data))) # stacking vertically\n",
        "        \n",
        "        # data with stretching and pitching\n",
        "        stretch_data = stretch(data)\n",
        "        data_stretch_pitch = pitch(stretch_data, sample_rate)\n",
        "        result = np.vstack((result, extract_features(data_stretch_pitch))) # stacking vertically\n",
        "    \n",
        "    return result"
      ],
      "metadata": {
        "id": "oWox6Bn04PZP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = [], []\n",
        "i = 0\n",
        "for path, emotion in zip(train_df.Path, train_df.Emotions):\n",
        "    feature = get_features(path, data_train=True)\n",
        "    if i%100 == 0:\n",
        "        print(str(i) + \" processed elements.\")\n",
        "    for ele in feature:\n",
        "        X_train.append(ele)\n",
        "        # appending emotion 3 times as we have made 3 augmentation techniques on each audio file.\n",
        "        Y_train.append(emotion)\n",
        "    i += 1\n",
        "\n",
        "dataset = pd.DataFrame(X_train)\n",
        "dataset['labels'] = Y_train\n",
        "dataset.to_csv('train_dataset_augmented.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZJpDl1g5iX5",
        "outputId": "3fc4f60e-7e7e-49e5-973f-821af0b69e22"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 processed elements.\n",
            "100 processed elements.\n",
            "200 processed elements.\n",
            "300 processed elements.\n",
            "400 processed elements.\n",
            "500 processed elements.\n",
            "600 processed elements.\n",
            "700 processed elements.\n",
            "800 processed elements.\n",
            "900 processed elements.\n",
            "1000 processed elements.\n",
            "1100 processed elements.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test, Y_test = [], []\n",
        "i = 0\n",
        "for path, emotion in zip(test_df.Path, test_df.Emotions):\n",
        "    feature = get_features(path, data_train=False)\n",
        "    if i%100 == 0:\n",
        "        print(str(i) + \" processed elements.\")\n",
        "    X_test.append(ele)\n",
        "    Y_test.append(emotion)\n",
        "    i += 1\n",
        "dataset = pd.DataFrame(X_test)\n",
        "dataset['labels'] = Y_test\n",
        "dataset.to_csv('test_dataset_augmented.csv', index=False)"
      ],
      "metadata": {
        "id": "BDYmJjwLDTvf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fb3327b-fedc-4749-c4f2-14106fdbba71"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 processed elements.\n",
            "100 processed elements.\n",
            "200 processed elements.\n",
            "300 processed elements.\n"
          ]
        }
      ]
    }
  ]
}